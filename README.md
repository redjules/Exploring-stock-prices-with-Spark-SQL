# Exploring stock prices with Spark SQL

# Project description
In this project, we initialize a Spark program, load datasets from a file, interact with the data using RDDs and DataFrames, and perform exploratory analysis using Spark SQL.

# Goals
In this project, we will:

- Become familiar with the Jupyter notebook environment.

- Be able to initialize a Spark application.

- Be able to create Spark Resilient Distributed Datasets.

- Be able to create Spark Data Frames in several ways.

- Be able to explore data sets with Spark SQL.

- Be able to write statistic queries and compare Spark DataFrames.

- Be able to store DataFrames in Parquet tables.


# Snapshots
  
